{"metadata": {"language_info": {"name": "python", "mimetype": "text/x-python", "nbconvert_exporter": "python", "pygments_lexer": "ipython2", "codemirror_mode": {"name": "ipython", "version": 2}, "file_extension": ".py", "version": "2.7.11"}, "kernelspec": {"display_name": "Python 2 with Spark 2.0", "name": "python2-spark20", "language": "python"}}, "nbformat_minor": 0, "cells": [{"metadata": {}, "source": "<table style=\"border: none\" align=\"left\">\n   <tr style=\"border: none\">\n      <th style=\"border: none\"><font face=\"verdana\" size=\"5\" color=\"black\"><b>Lab: Build, Save and Deploy Model to IBM Watson Machine Learning (WML)</b></th>\n      <th style=\"border: none\"><img src=\"https://github.com/pmservice/customer-satisfaction-prediction/blob/master/app/static/images/ml_icon_gray.png?raw=true\" alt=\"Watson Machine Learning icon\" height=\"40\" width=\"40\"></th>\n   </tr>\n</table>", "cell_type": "markdown"}, {"metadata": {}, "source": "\nThis notebook walks you through these steps:\n- Build a model\n- Save the model in the WML repository\n- Create a Deployment in WML\n- Invoke the deployed model with a Rest Client to test it", "cell_type": "markdown"}, {"metadata": {}, "source": "### Step 1: Connect to Object Storage", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": "# @hidden_cell\nfrom pyspark.sql import SparkSession\n\n# @hidden_cell\n# This function is used to setup the access of Spark to your Object Storage. The definition contains your credentials.\n# You might want to remove those credentials before you share your notebook.\ndef set_hadoop_config_with_credentials_78e95108d20b4b6eb7f928636070a5c2(name):\n    \"\"\"This function sets the Hadoop configuration so it is possible to\n    access data from Bluemix Object Storage using Spark\"\"\"\n\n    prefix = 'fs.swift.service.' + name\n    hconf = sc._jsc.hadoopConfiguration()\n    hconf.set(prefix + '.auth.url', 'https://identity.open.softlayer.com'+'/v3/auth/tokens')\n    hconf.set(prefix + '.auth.endpoint.prefix', 'endpoints')\n    hconf.set(prefix + '.tenant', '985d92f671ed450d8c4a864b0835135f')\n    hconf.set(prefix + '.username', '54d76d92adad41e8a2b7c2c24d32b3ce')\n    hconf.set(prefix + '.password', 'kb/^on8e8qLWE6~r')\n    hconf.setInt(prefix + '.http.port', 8080)\n    hconf.set(prefix + '.region', 'dallas')\n    hconf.setBoolean(prefix + '.public', False)\n\n# you can choose any name\nname = 'keystone'\nset_hadoop_config_with_credentials_78e95108d20b4b6eb7f928636070a5c2(name)\n\nspark = SparkSession.builder.getOrCreate()", "cell_type": "code", "execution_count": 34}, {"metadata": {}, "source": "### Step 2: Load Files", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": "# Customer Information\ncustomer = spark.read.format('csv')\\\n  .options(header='true', inferschema='true')\\\n  .load('swift://PredictChurn.' + name + '/customer.csv')\n  \n#Churn information    \ncustomer_churn = spark.read.format('csv')\\\n  .options(header='true', inferschema='true')\\\n  .load('swift://PredictChurn.' + name + '/churn.csv')", "cell_type": "code", "execution_count": 2}, {"metadata": {}, "source": "### Step 3: Merge Files", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": "merged=customer.join(customer_churn,customer['ID']==customer_churn['ID']).select(customer['*'],customer_churn['CHURN'])", "cell_type": "code", "execution_count": 3}, {"metadata": {}, "source": "### Step 4: Rename some columns\nThis step is to remove spaces from columns names", "cell_type": "markdown"}, {"outputs": [{"data": {"text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Gender</th>\n      <th>Status</th>\n      <th>Children</th>\n      <th>EstIncome</th>\n      <th>CarOwner</th>\n      <th>Age</th>\n      <th>LongDistance</th>\n      <th>International</th>\n      <th>Local</th>\n      <th>Dropped</th>\n      <th>Paymethod</th>\n      <th>LocalBilltype</th>\n      <th>LongDistanceBilltype</th>\n      <th>Usage</th>\n      <th>RatePlan</th>\n      <th>CHURN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>F</td>\n      <td>S</td>\n      <td>1</td>\n      <td>38000.00</td>\n      <td>N</td>\n      <td>24.393333</td>\n      <td>23.56</td>\n      <td>0</td>\n      <td>206.08</td>\n      <td>0</td>\n      <td>CC</td>\n      <td>Budget</td>\n      <td>Intnl_discount</td>\n      <td>229.64</td>\n      <td>3</td>\n      <td>T</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>M</td>\n      <td>M</td>\n      <td>2</td>\n      <td>29616.00</td>\n      <td>N</td>\n      <td>49.426667</td>\n      <td>29.78</td>\n      <td>0</td>\n      <td>45.50</td>\n      <td>0</td>\n      <td>CH</td>\n      <td>FreeLocal</td>\n      <td>Standard</td>\n      <td>75.29</td>\n      <td>2</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>M</td>\n      <td>M</td>\n      <td>0</td>\n      <td>19732.80</td>\n      <td>N</td>\n      <td>50.673333</td>\n      <td>24.81</td>\n      <td>0</td>\n      <td>22.44</td>\n      <td>0</td>\n      <td>CC</td>\n      <td>FreeLocal</td>\n      <td>Standard</td>\n      <td>47.25</td>\n      <td>3</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11</td>\n      <td>M</td>\n      <td>S</td>\n      <td>2</td>\n      <td>96.33</td>\n      <td>N</td>\n      <td>56.473333</td>\n      <td>26.13</td>\n      <td>0</td>\n      <td>32.88</td>\n      <td>1</td>\n      <td>CC</td>\n      <td>Budget</td>\n      <td>Standard</td>\n      <td>59.01</td>\n      <td>1</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14</td>\n      <td>F</td>\n      <td>M</td>\n      <td>2</td>\n      <td>52004.80</td>\n      <td>N</td>\n      <td>25.140000</td>\n      <td>5.03</td>\n      <td>0</td>\n      <td>23.11</td>\n      <td>0</td>\n      <td>CH</td>\n      <td>Budget</td>\n      <td>Intnl_discount</td>\n      <td>28.14</td>\n      <td>1</td>\n      <td>F</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   ID Gender Status  Children  EstIncome CarOwner        Age  LongDistance  \\\n0   1      F      S         1   38000.00        N  24.393333         23.56   \n1   6      M      M         2   29616.00        N  49.426667         29.78   \n2   8      M      M         0   19732.80        N  50.673333         24.81   \n3  11      M      S         2      96.33        N  56.473333         26.13   \n4  14      F      M         2   52004.80        N  25.140000          5.03   \n\n   International   Local  Dropped Paymethod LocalBilltype  \\\n0              0  206.08        0        CC        Budget   \n1              0   45.50        0        CH     FreeLocal   \n2              0   22.44        0        CC     FreeLocal   \n3              0   32.88        1        CC        Budget   \n4              0   23.11        0        CH        Budget   \n\n  LongDistanceBilltype   Usage  RatePlan CHURN  \n0       Intnl_discount  229.64         3     T  \n1             Standard   75.29         2     F  \n2             Standard   47.25         3     F  \n3             Standard   59.01         1     F  \n4       Intnl_discount   28.14         1     F  "}, "metadata": {}, "output_type": "execute_result", "execution_count": 4}], "metadata": {"collapsed": false}, "source": "merged = merged.withColumnRenamed(\"Est Income\", \"EstIncome\").withColumnRenamed(\"Car Owner\",\"CarOwner\")\nmerged.toPandas().head()", "cell_type": "code", "execution_count": 4}, {"metadata": {}, "source": "### Step 5: Build the Spark pipeline and the Random Forest model\n\"Pipeline\" is an API in SparkML that's used for building models.\nAdditional information on SparkML: https://spark.apache.org/docs/2.0.2/ml-guide.html", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": "from pyspark.ml.feature import StringIndexer, VectorIndexer\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import RandomForestClassifier\n\n# Prepare string variables so that they can be used by the decision tree algorithm\nstringIndexer1 = StringIndexer(inputCol='Gender', outputCol='GenderEncoded')\nstringIndexer2 = StringIndexer(inputCol='Status',outputCol='StatusEncoded')\nstringIndexer3 = StringIndexer(inputCol='CarOwner',outputCol='CarOwnerEncoded')\nstringIndexer4 = StringIndexer(inputCol='Paymethod',outputCol='PaymethodEncoded')\nstringIndexer5 = StringIndexer(inputCol='LocalBilltype',outputCol='LocalBilltypeEncoded')\nstringIndexer6 = StringIndexer(inputCol='LongDistanceBilltype',outputCol='LongDistanceBilltypeEncoded')\nstringIndexer7 = StringIndexer(inputCol='CHURN', outputCol='label')\n\n# Pipelines API requires that input variables are passed in  a vector\nassembler = VectorAssembler(inputCols=[\"GenderEncoded\", \"StatusEncoded\", \"CarOwnerEncoded\", \"PaymethodEncoded\", \"LocalBilltypeEncoded\", \\\n                                       \"LongDistanceBilltypeEncoded\", \"Children\", \"EstIncome\", \"Age\", \"LongDistance\", \"International\", \"Local\",\\\n                                      \"Dropped\",\"Usage\",\"RatePlan\"], outputCol=\"features\")\n\n\n# instantiate the algorithm, take the default settings\nrf=RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n\n#pipeline = Pipeline(stages=[stringIndexer1, stringIndexer2, stringIndexer3, assembler, rf])\npipeline = Pipeline(stages=[stringIndexer1,stringIndexer2,stringIndexer3,stringIndexer4,stringIndexer5,stringIndexer6,stringIndexer7, assembler, rf])", "cell_type": "code", "execution_count": 5}, {"outputs": [], "metadata": {"collapsed": true}, "source": "# Split data into train and test datasets\ntrain, test = merged.randomSplit([80.0,20.0], seed=6)", "cell_type": "code", "execution_count": 6}, {"outputs": [], "metadata": {"collapsed": false}, "source": "# Build models\nmodel = pipeline.fit(train)", "cell_type": "code", "execution_count": 7}, {"metadata": {"collapsed": true}, "source": "### Step 6: Score the test data set", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": "results = model.transform(test)", "cell_type": "code", "execution_count": 8}, {"metadata": {}, "source": "### Step 7: Model Evaluation ", "cell_type": "markdown"}, {"outputs": [{"name": "stdout", "output_type": "stream", "text": "Precision model1 = 0.92.\n"}], "metadata": {"collapsed": false}, "source": "print 'Precision model1 = {:.2f}.'.format(results.filter(results.label == results.prediction).count() / float(results.count()))", "cell_type": "code", "execution_count": 9}, {"outputs": [{"name": "stdout", "output_type": "stream", "text": "Area under ROC curve = 0.92.\n"}], "metadata": {"collapsed": false}, "source": "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\nprint 'Area under ROC curve = {:.2f}.'.format(evaluator.evaluate(results))", "cell_type": "code", "execution_count": 10}, {"metadata": {}, "source": "### Step 8: Save Model in WML repository\n\nIn this section you will store your model in the Watson Machine Learning (WML) repository by using Python client libraries.\n* <a href=\"https://console.ng.bluemix.net/docs/services/PredictiveModeling/index.html\">WML Documentation</a>\n* <a href=\"http://watson-ml-api.mybluemix.net/\">WML API</a> \n<br/>\n\nFirst, you must import client libraries.", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": "from repository.mlrepositoryclient import MLRepositoryClient\nfrom repository.mlrepositoryartifact import MLRepositoryArtifact", "cell_type": "code", "execution_count": 11}, {"metadata": {}, "source": "Put your authentication information from your instance of the Watson Machine Learning service in <a href=\"https://console.ng.bluemix.net/dashboard/apps/\" target=\"_blank\">Bluemix</a> in the next cell. You can find your information on the **Service Credentials** tab of your service instance in Bluemix.\n\n<span style=\"color:red\">Replace the service_path and credentials with your own information</span>\n\nservice_path=[your url]<br/>\nusername=[your username]<br/>\npassword=[your password]<br/>", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": "# @hidden_cell\nservice_path = 'https://ibm-watson-ml.mybluemix.net'\nusername = '9b9d7782-18c7-4244-bd7c-24f9b6db5e4b'\npassword = 'c9a843e7-1e3d-40f8-b054-751c46024c38'", "cell_type": "code", "execution_count": 35}, {"metadata": {}, "source": "Authorize the repository client:", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": "ml_repository_client = MLRepositoryClient(service_path)\nml_repository_client.authorize(username, password)", "cell_type": "code", "execution_count": 29}, {"metadata": {}, "source": "Create the model artifact (abstraction layer).\n\n<b>Tip:</b> The MLRepositoryArtifact method expects a trained model object, training data, and a model name. (It is this model name that is displayed by the Watson Machine Learning service).\n", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": "model_artifact = MLRepositoryArtifact(model, training_data=train, name=\"Predict Customer Churn\")", "cell_type": "code", "execution_count": 30}, {"metadata": {}, "source": "Save pipeline and model artifacts to your Watson Machine Learning instance:", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": true}, "source": "saved_model = ml_repository_client.models.save(model_artifact)", "cell_type": "code", "execution_count": 31}, {"outputs": [{"name": "stdout", "output_type": "stream", "text": "modelType: sparkml-model-2.0\ncreationTime: 2017-06-22 16:12:36.014000+00:00\nmodelVersionHref: https://ibm-watson-ml.mybluemix.net/v2/artifacts/models/fb65f468-1d68-4a53-869f-ce5caf6be5d6/versions/d0f9287d-5731-4b4d-8255-2f2707df4911\nlabel: CHURN\n"}], "metadata": {"collapsed": false}, "source": "# Print the saved model properties\nprint \"modelType: \" + saved_model.meta.prop(\"modelType\")\nprint \"creationTime: \" + str(saved_model.meta.prop(\"creationTime\"))\nprint \"modelVersionHref: \" + saved_model.meta.prop(\"modelVersionHref\")\nprint \"label: \" + saved_model.meta.prop(\"label\")", "cell_type": "code", "execution_count": 32}, {"metadata": {}, "source": "### Step 9:  Generate Authorization Token for Invoking the model", "cell_type": "markdown"}, {"outputs": [], "metadata": {"collapsed": false}, "source": "import urllib3, requests, json\n\nheaders = urllib3.util.make_headers(basic_auth='{}:{}'.format(username, password))\nurl = '{}/v2/identity/token'.format(service_path)\nresponse = requests.get(url, headers=headers)\nmltoken = json.loads(response.text).get('token')\nprint mltoken", "cell_type": "code", "execution_count": 36}, {"metadata": {}, "source": "#### Step 9.1 Copy the generated token into your notepad", "cell_type": "markdown"}, {"metadata": {}, "source": "### Step 10:  Go to WML in Bluemix to create a Deployment Endpoint and Test the Deployed model\n\n* In your <a href=\"https://console.ng.bluemix.net/dashboard/apps/\" target=\"_blank\">Bluemix</a> dashboard, click into your WML Service and click the **Launch Dashboard** button under Watson Machine Learing.\n![WML Launch Dashboard](https://raw.githubusercontent.com/yfphoon/dsx_demo/master/WML_Launch_Dashboard.png)\n\n<br/>\n* You should see your deployed model in the **Models** tab\n", "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "source": "* Under *Actions*, click on the 3 ellipses and click ***Create Deployment***.  Give your deployment configuration a unique name, e.g. \"Predict Customer Churn Deply\", accept the defaults and click **Save**.\n<br/>\n<br/>\n* In the *Deployments tab*, under *Actions*, click **View Details**\n<br/>\n<br/>\n* Scoll down to **API Details**, copy the value of the **Scoring Endpoint** into your notepad.  (e.g. \thttps://ibm-watson-ml.mybluemix.net/v2/published_models/64fd0462-3f8a-4b42-820b-59a4da9b7dc6/deployments/7d9995ed-7daf-4cfd-b40f-37cb8ab3d88f/online)", "cell_type": "markdown"}, {"metadata": {}, "source": "### Step 11:  Invoke the model with a REST Client, e.g. https://client.restlet.com/\n\nIn the REST client interface enter the following information:\n\n1. Protocol:  **HTTPS**\n<br/>\n<br/>\n\n2. URI: **your scoring endpoint**  (Step 10)\n<br/>\n<br/>\n3. method: **POST**\n<br/>\n<br/>\n4. Authorization:  **your generated token** (Step 9). Hint: Add \"Basic authorization\" with a dummy value of 1 in the userid field. Then replace the value with the token. \n<br/>\n<br/>\n5. Content Type: **application/JSON**\n<br/>\n<br/>\n6. JSON Body:<br/>**{\n  \"fields\": [\n    \"ID\",\"Gender\",\"Status\",\"Children\",\"EstIncome\",\"CarOwner\",\"Age\",\"LongDistance\",\"International\",\"Local\",\"Dropped\",\"Paymethod\",\"LocalBilltype\",\"LongDistanceBilltype\",\"Usage\",\"RatePlan\"\n  ],\n  \"values\": [ \n  [999,\"F\",\"M\",2.0,77551.100000,\"Y\",33.600000,20.530000,0.000000,41.890000,1.000000,\"CC\",\"Budget\",\"Intnl_discount\",62.420000,2.000000]\n  ]\n} **\n<br/>\n<br/>\n7. Click **Send*\n\nScroll down to the **RESPONSE** section to see the scored results\n\n**Note:** The values in the JSON body does not include the label.\n", "cell_type": "markdown"}, {"metadata": {}, "source": "**Sample REST Client Input**\n![Rest Client Input](https://github.com/ibm-cloud-architecture/refarch-data-science/blob/master/static/imgs/RestRequest.PNG?raw=true)", "cell_type": "markdown"}, {"metadata": {"collapsed": true}, "source": "You have come to the end of this notebook", "cell_type": "markdown"}, {"metadata": {}, "source": "\n**Sidney Phoon**\n<br/>\nyfphoon@us.ibm.com\n<br/>\nApril 25, 2017", "cell_type": "markdown"}], "nbformat": 4}